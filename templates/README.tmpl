# {{.ProjectName}}

A Go project generated using the Go Project Generator with clean architecture principles.

## Project Structure

```
.
â”œâ”€â”€ cmd/                          # Entry point
â”‚   â””â”€â”€ main.go                   # Application entry
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ app/                      # Application server & routing
â”‚   â”‚   â”œâ”€â”€ server.go             # Server setup
â”‚   â”‚   â”œâ”€â”€ routes.go             # Route registration
â”‚   â”‚   â””â”€â”€ bootstrap.go          # Dependency initialization
â”‚   â”œâ”€â”€ deps/                     # Dependency management
â”‚   â”‚   â”œâ”€â”€ deps.go               # Dependency container
â”‚   â”‚   â””â”€â”€ config.go             # Configuration loading
{{- if .IncludeExample}}
â”‚   â”œâ”€â”€ domain/                   # Domain entities (pure business models)
â”‚   â”‚   â””â”€â”€ entity.go             # Business models
â”‚   â”œâ”€â”€ usecase/                  # Business logic (application layer)
â”‚   â”‚   â””â”€â”€ user_usecase.go       # User use cases
â”‚   â”œâ”€â”€ adapter/                  # Adapters (input/output)
â”‚   â”‚   â”œâ”€â”€ handler/              # HTTP handlers (input adapter)
â”‚   â”‚   â”‚   â””â”€â”€ user_handler.go   # User HTTP endpoints
{{- if index .Includes "cron"}}
â”‚   â”‚   â”œâ”€â”€ job/                  # Scheduled jobs (input adapter)
â”‚   â”‚   â”‚   â””â”€â”€ example_job.go    # Example cron job
{{- end}}
{{- if or (index .Includes "rabbitmq") (index .Includes "kafka") (index .Includes "activemq")}}
â”‚   â”‚   â””â”€â”€ consumer/             # Message consumers (input adapter)
{{- if index .Includes "rabbitmq"}}
â”‚   â”‚       â”œâ”€â”€ rabbitmq_consumer.go # RabbitMQ consumer
{{- end}}
{{- if index .Includes "kafka"}}
â”‚   â”‚       â”œâ”€â”€ kafka_consumer.go    # Kafka consumer
{{- end}}
{{- if index .Includes "activemq"}}
â”‚   â”‚       â””â”€â”€ activemq_consumer.go # ActiveMQ consumer
{{- end}}
{{- end}}
â”‚   â”œâ”€â”€ infrastructure/           # Infrastructure layer (output adapters)
â”‚   â”‚   â””â”€â”€ repository/           # Data access implementations
â”‚   â”‚       â”œâ”€â”€ user_repository.go    # User data operations
â”‚   â”‚       â”œâ”€â”€ cache_repository.go   # Cache operations
â”‚   â”‚       â””â”€â”€ models/           # Database models (GORM)
â”‚   â”‚           â””â”€â”€ user_model.go # DB-specific user model
â”‚   â”œâ”€â”€ errors/                   # Custom error handling
â”‚   â”‚   â””â”€â”€ errors.go             # AppError system
â”‚   â”œâ”€â”€ middleware/               # HTTP middleware
â”‚   â”‚   â”œâ”€â”€ logging.go            # Request/response logging
â”‚   â”‚   â”œâ”€â”€ tracing.go            # Distributed tracing
â”‚   â”‚   â””â”€â”€ ratelimit.go          # Rate limiting
{{- end}}
â”‚   â””â”€â”€ infrastructure/           # External services
{{- if or (index .Includes "postgres") (index .Includes "mysql") (index .Includes "redis") (index .Includes "logrus") (index .Includes "resty") (index .Includes "mapstructure") (index .Includes "validator") (index .Includes "rabbitmq") (index .Includes "kafka") (index .Includes "activemq") (index .Includes "cron") (index .Includes "opentelemetry") }}
â”‚       - Integrations:
{{- if index .Includes "postgres"}}
â”‚         â€¢ postgres/              (PostgreSQL setup)
{{- end}}
{{- if index .Includes "mysql"}}
â”‚         â€¢ mysql/                 (MySQL setup)
{{- end}}
{{- if index .Includes "redis"}}
â”‚         â€¢ redis/                 (Redis setup)
{{- end}}
{{- if index .Includes "logrus"}}
â”‚         â€¢ logrus/                (Logging setup)
{{- end}}
{{- if index .Includes "resty"}}
â”‚         â€¢ resty/                 (HTTP client setup)
{{- end}}
{{- if index .Includes "mapstructure"}}
â”‚         â€¢ mapstructure/          (Mapstructure decoder helpers)
{{- end}}
{{- if index .Includes "validator"}}
â”‚         â€¢ validator/             (Request validation helpers)
{{- end}}
{{- if index .Includes "rabbitmq"}}
â”‚         â€¢ rabbitmq/              (RabbitMQ setup)
{{- end}}
{{- if index .Includes "kafka"}}
â”‚         â€¢ kafka/                 (Kafka producer/consumer setup)
{{- end}}
{{- if index .Includes "activemq"}}
â”‚         â€¢ activemq/              (ActiveMQ STOMP setup)
{{- end}}
{{- if index .Includes "cron"}}
â”‚         â€¢ cron/                  (Cron scheduler setup)
{{- end}}
{{- if index .Includes "opentelemetry"}}
â”‚         â€¢ opentelemetry/         (OpenTelemetry tracing)
{{- end}}
{{- end}}
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.json               # Configuration file
â”œâ”€â”€ Dockerfile                    # Docker image definition
â”œâ”€â”€ .env.example                  # Environment variables example
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ go.mod                        # Go module definition
â”œâ”€â”€ go.sum                        # Dependency checksums
â””â”€â”€ README.md                     # This file
```

## Prerequisites

- Go 1.20+

**Built-in features** (no additional setup required):
- ðŸ”§ **Viper**: Configuration management with auto env binding
- ðŸ“ **Logrus**: Structured JSON logging across all layers
- âš¡ **Middleware**: Logging, tracing, and rate limiting
{{- if index .Includes "postgres"}}
- PostgreSQL
{{- end}}
{{- if index .Includes "mysql"}}
- MySQL
{{- end}}
{{- if index .Includes "redis"}}
- Redis
{{- end}}
{{- if index .Includes "rabbitmq"}}
- RabbitMQ
{{- end}}
{{- if index .Includes "kafka"}}
- Kafka broker (e.g., Apache Kafka 3.x)
{{- end}}
{{- if index .Includes "activemq"}}
- ActiveMQ / ActiveMQ Artemis (STOMP endpoint)
{{- end}}
{{- if index .Includes "opentelemetry"}}
- OTLP collector/endpoint (optional, for tracing export)
{{- end}}

## Setup

### 1. Install Dependencies

```bash
go mod download
go mod tidy
```

### 2. Configuration (Viper)

This project uses **Viper** for configuration management with automatic environment variable binding.

**Setup configuration:**

```bash
# 1. Copy environment template
cp .env.example .env

# 2. Edit .env with your values
nano .env

# 3. Edit config/config.json for defaults (optional)
nano config/config.json
```

**How Viper loads config:**
1. Reads `config/config.json` for base configuration
2. Automatically binds environment variables (nested keys: `redis.addr` â†’ `REDIS_ADDR`)
3. ENV variables override config file values
4. Applies code-level defaults for missing values

### 3. Generate Swagger Documentation

This project includes Swagger/OpenAPI annotations in handler methods. Generate the documentation:

```bash
# Install swag CLI tool (first time only)
go install github.com/swaggo/swag/cmd/swag@latest

# Generate Swagger docs
swag init -g cmd/main.go -o docs
```

After starting the server, access Swagger UI at:
- **Swagger UI**: `http://localhost:8080/swagger/index.html`
- **OpenAPI JSON**: `http://localhost:8080/swagger/doc.json`

> **Note**: Re-run `swag init` after modifying handler annotations or adding new endpoints.

{{- if or (index .Includes "postgres") (index .Includes "mysql") (index .Includes "redis") (index .Includes "rabbitmq")}}
### 4. Start Services (Docker Compose)

Create a `docker-compose.yml`:

```yaml
version: '3.8'

services:
{{- if index .Includes "postgres"}}
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: example
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

{{- end}}
{{- if index .Includes "mysql"}}
  mysql:
    image: mysql:8
    environment:
      MYSQL_DATABASE: example
      MYSQL_ROOT_PASSWORD: root
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql

{{- end}}
{{- if index .Includes "redis"}}
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

{{- end}}
{{- if index .Includes "rabbitmq"}}
  rabbitmq:
    image: rabbitmq:3-management-alpine
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

{{- end}}
{{- if index .Includes "kafka"}}
  zookeeper:
    image: bitnami/zookeeper:3.9
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"

  kafka:
    image: bitnami/kafka:3.7
    depends_on:
      - zookeeper
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - ALLOW_PLAINTEXT_LISTENER=yes
    ports:
      - "9092:9092"

{{- end}}
{{- if index .Includes "activemq"}}
  activemq:
    image: rmohr/activemq:5.17.6
    ports:
      - "61613:61613"   # STOMP
      - "8161:8161"     # Admin UI

{{- end}}

volumes:
{{- if index .Includes "postgres"}}
  postgres_data:
{{- end}}
{{- if index .Includes "mysql"}}
  mysql_data:
{{- end}}
{{- if index .Includes "redis"}}
  redis_data:
{{- end}}
{{- if index .Includes "rabbitmq"}}
  rabbitmq_data:
{{- end}}
{{- if index .Includes "kafka"}}
  kafka_data:
{{- end}}
```

Start services:

```bash
docker-compose up -d
```

{{- end}}
## Running

### Development

```bash
go run cmd/main.go
```

The server will start on the configured port (default: 8080).

### With Custom Configuration (Viper)

Viper automatically loads `config/config.json` and applies environment variable overrides:

```bash
# Method 1: Direct environment variables
LOG_LEVEL=debug ECHO_PORT=3000 go run cmd/main.go

# Method 2: Source .env file (Viper compatible)
source .env && go run cmd/main.go

# Method 3: Use direnv or similar tools
# .envrc
export LOG_LEVEL=debug
export ECHO_PORT=3000
```

**Priority order**: `ENV variables` â†’ `config.json` â†’ `code defaults`

### Build for Production

```bash
go build -o {{.ProjectName}} cmd/main.go
./{{.ProjectName}}
```

### Docker

Build the image:

```bash
docker build -t {{.ProjectName}}:latest .
```

Run the container:

```bash
docker run -d \
  --name {{.ProjectName}} \
  -p 8080:8080 \
  -e ECHO_PORT=8080 \
  {{- if index .Includes "postgres"}}
  -e POSTGRES_DSN="postgres://user:pass@postgres:5432/db" \
  {{- end}}
  {{.ProjectName}}:latest
```

## API Endpoints

{{- if .IncludeExample}}

### Interactive API Documentation (Swagger)

Access the interactive Swagger UI to explore and test all API endpoints:

```
http://localhost:8080/swagger/index.html
```

Swagger UI provides:
- ðŸ“‹ Complete API documentation
- ðŸ§ª Interactive testing interface
- ðŸ“ Request/response examples
- âœ… Request validation

> **Tip**: Use Swagger UI to test endpoints without writing curl commands!

### Health Check

```bash
curl http://localhost:8080/health
```

Response:
```json
{
  "status": "ok"
}
```

### Get User

```bash
curl http://localhost:8080/api/v1/users/1
```

Response:
```json
{
  "id": 1,
  "name": "John Doe",
  "email": "john@example.com"
}
```

{{- end}}

## Configuration

This project uses **Viper** (built-in) for powerful configuration management with automatic environment variable binding.

### Configuration Management (Built-in - Viper)

Viper provides:
- ðŸ“ **Multiple formats**: JSON, YAML, TOML, ENV files (default: JSON)
- ðŸ”„ **Auto env binding**: Nested config keys automatically map to environment variables
- ðŸŽ¯ **Type-safe**: Strong typing with struct unmarshaling
- ðŸ”€ **Priority order**: ENV vars override config file values

**How it works:**

```go
// Config structure
type Config struct {
    Log *LogConfig `json:"log" mapstructure:"log"`
    Echo *EchoConfig `json:"echo" mapstructure:"echo"`
    Redis *RedisConfig `json:"redis" mapstructure:"redis"`
}

// Loaded from: config/config.json
// Override with ENV: LOG_LEVEL, ECHO_PORT, REDIS_ADDR
```

**Key mapping:**
- Nested keys use dot notation in JSON: `redis.addr`
- Automatically converted to ENV format: `REDIS_ADDR`
- Case-insensitive matching

### Environment Variables

See `.env.example` for all available configuration options.

**Common variables:**

Framework:
- `{{if eq .Framework "echo"}}ECHO_HOST`, `ECHO_PORT`, `ECHO_DEBUG{{else if eq .Framework "gin"}}GIN_HOST`, `GIN_PORT`, `GIN_MODE{{else if eq .Framework "fiber"}}FIBER_HOST`, `FIBER_PORT{{end}}`

Logging (built-in):
- `LOG_LEVEL` - Logging level (debug, info, warn, error) - default: `info`
{{- if index .Includes "postgres"}}
- `POSTGRES_DSN` - PostgreSQL connection string
{{- end}}
{{- if index .Includes "mysql"}}
- `MYSQL_DSN` - MySQL connection string
{{- end}}
{{- if index .Includes "redis"}}
- `REDIS_ADDR` - Redis address (host:port)
{{- end}}
{{- if index .Includes "rabbitmq"}}
- `RABBITMQ_URL` - RabbitMQ connection URL
{{- end}}
{{- if index .Includes "kafka"}}
- `KAFKA_BROKERS`, `KAFKA_TOPIC`, `KAFKA_GROUPID`, `KAFKA_BALANCER`
{{- end}}
{{- if index .Includes "activemq"}}
- `ACTIVEMQ_ADDR`, `ACTIVEMQ_LOGIN`, `ACTIVEMQ_PASSCODE`
{{- end}}
{{- if index .Includes "opentelemetry"}}
- `OPENTELEMETRY_SERVICENAME`, `OPENTELEMETRY_ENDPOINT`, `OPENTELEMETRY_INSECURE`, `OPENTELEMETRY_SAMPLERATIO`
{{- end}}

**Configuration examples:**

```bash
# config/config.json
{
  "log": {"level": "info"},
  "echo": {"host": "0.0.0.0", "port": 8080},
  "redis": {"addr": "localhost:6379"}
}

# Override via environment variables
export LOG_LEVEL=debug
export ECHO_PORT=3000
export REDIS_ADDR=redis-server:6379

# Viper automatically applies ENV overrides
# Priority: ENV vars > config file > defaults
```

> **Tip:** All nested keys from `config/config.json` are automatically mapped to environment variables by converting dots to underscores (e.g. `redis.addr` â†’ `REDIS_ADDR`). Viper handles this conversion seamlessly!

## Architecture

This project follows **Clean Architecture** principles with proper separation of concerns:

### Layers

- **Domain**: Pure business entities (no external dependencies, no GORM tags)
- **Usecase**: Application-specific business rules
- **Adapter** (Input/Output Adapters):
  - **Handler**: HTTP request/response handling, DTOs with validation
  - **Job**: Scheduled jobs (cron)
  - **Consumer**: Message queue consumers (RabbitMQ, Kafka)
- **Infrastructure/Repository**: Data access implementations, database models
- **Errors**: Custom structured error handling with `AppError`
- **Middleware**: Cross-cutting concerns (logging, tracing, rate limiting)

### Dependency Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Input Adapters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP Request â†’ Handler               â”‚
â”‚ Cron Schedule â†’ Job                  â”‚
â”‚ Message Queue â†’ Consumer             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
         Usecase (business logic)
               â†“
         Repository (data access)
               â†“
         Database/Cache
```

**Clean Architecture Principle**: Dependencies point inward
- Adapters depend on Usecases
- Usecases depend on Domain
- Infrastructure implements interfaces defined in Domain

### Key Design Patterns

1. **DTO Pattern**: Request/Response DTOs in handler layer, separate from domain entities
2. **Repository Pattern**: Abstracts data access with models layer for GORM entities
3. **Dependency Injection**: All dependencies injected via constructors
4. **Context Propagation**: `context.Context` passed through all layers for cancellation, timeouts, and tracing

## Logging (Built-in)

This project includes **structured logging** with Logrus across all layers:

### Log Levels
- **DEBUG**: Detailed information for debugging (cache operations, detailed flow)
- **INFO**: General informational messages (user created, operation completed)
- **WARN**: Warning messages (not found, validation errors)
- **ERROR**: Error messages (database failures, external API errors)

### Configuration

Set log level via environment variable or config:

```bash
LOG_LEVEL=debug go run cmd/main.go
```

Or in `config/config.json`:
```json
{
  "log": {
    "level": "info"
  }
}
```

### Log Format

Logs are output in JSON format for easy parsing:

```json
{
  "level": "info",
  "msg": "User retrieved successfully",
  "user_id": 123,
  "email": "john@example.com",
  "time": "2025-11-18T10:30:00+07:00"
}
```

### Logging in Each Layer

**Handler Layer** - HTTP request/response logging:
```go
h.log.WithField("user_id", id).Info("Fetching user")
```

**Usecase Layer** - Business logic logging:
```go
u.log.WithFields(logrus.Fields{
    "email": user.Email,
    "name":  user.Name,
}).Info("Creating new user")
```

**Repository Layer** - Data access logging:
```go
r.log.WithField("user_id", id).Debug("Fetching user from database")
```

## Development

### Adding a New Endpoint

1. **Define DTO** in `internal/adapter/handler/user_handler.go` with validation tags:
```go
type CreateUserRequest struct {
    Name  string `json:"name" validate:"required,min=2,max=100"`
    Email string `json:"email" validate:"required,email"`
}
```

2. **Add Handler Method** with logging and error handling:
```go
func (h *UserHandler) CreateUser(c echo.Context) error {
    h.log.Info("Creating user")
    
    var req CreateUserRequest
    if err := c.Bind(&req); err != nil {
        h.log.WithError(err).Warn("Invalid request format")
        return c.JSON(http.StatusBadRequest, map[string]string{"error": err.Error()})
    }
    
    // Validate using go-playground/validator
    if err := h.validator.Struct(&req); err != nil {
        h.log.WithError(err).Warn("Validation failed")
        return c.JSON(http.StatusBadRequest, map[string]string{"error": err.Error()})
    }
    
    // Convert DTO to domain entity
    user := req.ToUser()
    
    // Call usecase
    if err := h.userUsecase.CreateUser(c.Request().Context(), user); err != nil {
        h.log.WithError(err).Error("Failed to create user")
        return c.JSON(http.StatusInternalServerError, map[string]string{"error": err.Error()})
    }
    
    h.log.WithField("user_id", user.ID).Info("User created successfully")
    return c.JSON(http.StatusCreated, user)
}
```

3. **Register Route** in `internal/app/routes.go`:
```go
api.POST("/users", userHandler.CreateUser)
```

4. **Implement Business Logic** in `internal/usecase/user_usecase.go`:
```go
func (u *UserUsecase) CreateUser(ctx context.Context, user *domain.User) error {
    u.log.WithField("email", user.Email).Info("Creating user")
    return u.userRepo.Create(ctx, user)
}
```

5. **Define Database Model** in `internal/infrastructure/repository/models/user_model.go`:
```go
type UserModel struct {
    ID    int64  `gorm:"primaryKey"`
    Name  string `gorm:"type:varchar(255);not null"`
    Email string `gorm:"uniqueIndex;not null"`
}

func (m *UserModel) TableName() string {
    return "users"
}
```

6. **Implement Repository** in `internal/infrastructure/repository/user_repository.go`:
```go
func (r *UserRepositoryImpl) Create(ctx context.Context, user *domain.User) error {
    r.log.WithField("email", user.Email).Debug("Creating user in database")
    
    model := models.FromDomain(user)
    if err := r.getDB().WithContext(ctx).Create(model).Error; err != nil {
        r.log.WithError(err).Error("Failed to create user")
        return err
    }
    
    user.ID = model.ID
    r.log.WithField("user_id", user.ID).Info("User created in database")
    return nil
}
```

### Error Handling with AppError

Use the custom `AppError` system for structured error handling:

```go
import "{{.ModuleName}}/internal/errors"

// Not found error
return errors.NotFound("User").WithContext("user_id", id)

// Validation error
return errors.ValidationError("Invalid email format")

// Database error
return errors.Database("INSERT user", err).WithContext("email", user.Email)

// Internal error with wrapped error
return errors.Internal("Failed to process user", err)
```

### Updating Swagger Documentation

After adding or modifying handlers, regenerate Swagger docs:

```bash
# Regenerate Swagger documentation
swag init -g cmd/main.go -o docs

# Restart the server to see changes
go run cmd/main.go
```

**Adding Swagger Annotations to Handlers:**

```go
// GetUser godoc
// @Summary Retrieve user by ID
// @Description Returns user information for the provided identifier
// @Tags users
// @Accept json
// @Produce json
// @Param id path int true "User ID"
// @Success 200 {object} UserResponse
// @Failure 400 {object} ErrorResponse "Invalid ID format"
// @Failure 404 {object} ErrorResponse "User not found"
// @Failure 500 {object} ErrorResponse "Internal server error"
// @Router /api/v1/users/{id} [get]
func (h *UserHandler) GetUser(c echo.Context) error {
    // handler implementation
}
```

Access the interactive API documentation at `http://localhost:8080/swagger/index.html`

{{- if index .Includes "rabbitmq"}}
### Using RabbitMQ

> **Note**: When you select RabbitMQ, a consumer template is automatically generated at `internal/adapter/consumer/rabbitmq_consumer.go`. You can customize it for your use case.

**Starting the RabbitMQ Consumer (Clean Architecture):**

```go
// In cmd/main.go or internal/app/bootstrap.go
import (
    "{{.ModuleName}}/internal/adapter/consumer"
    "{{.ModuleName}}/internal/usecase"
)

// 1. Initialize usecases (business logic layer)
userUsecase := usecase.NewUserUsecase(userRepo, cacheRepo, d.Log)

// 2. Inject usecase into consumer (dependency injection)
if d.RabbitMQ != nil {
    rabbitConsumer := consumer.NewRabbitMQConsumer(d, userUsecase)
    
    // Run as background goroutine
    go rabbitConsumer.Run()
    
    log.Println("RabbitMQ consumer started")
}
```

**Clean Architecture Flow:**
```
RabbitMQ Message â†’ Consumer (Adapter) â†’ Usecase (Business Logic) â†’ Repository â†’ Database
```

**Consumer calls usecase methods:**
```go
// Inside consumer handler
func (c *RabbitMQConsumer) handleUserCreated(ctx context.Context, event map[string]interface{}) error {
    userID := int64(event["user_id"].(float64))
    
    // Consumer calls usecase (following Clean Architecture)
    user, err := c.userUsecase.GetUser(ctx, userID)
    if err != nil {
        return err
    }
    
    // Additional business logic via usecases
    return nil
}
```

**Example 1: Producer - Publishing Messages**

```go
// In your usecase or handler
func (u *UserUsecase) PublishUserEvent(ctx context.Context, userID int64, event string) error {
    u.log.WithFields(logrus.Fields{
        "user_id": userID,
        "event":   event,
    }).Info("Publishing user event to RabbitMQ")

    // Create a channel
    ch, err := u.deps.RabbitMQ.Conn.Channel()
    if err != nil {
        u.log.WithError(err).Error("Failed to create RabbitMQ channel")
        return fmt.Errorf("failed to create channel: %w", err)
    }
    defer ch.Close()

    // Declare a queue (idempotent)
    queueName := "user-events"
    q, err := rabbitmq.DeclareQueue(ch, queueName, true)
    if err != nil {
        u.log.WithError(err).Error("Failed to declare queue")
        return fmt.Errorf("failed to declare queue: %w", err)
    }

    // Prepare message
    message := map[string]interface{}{
        "user_id":   userID,
        "event":     event,
        "timestamp": time.Now().Unix(),
    }
    body, _ := json.Marshal(message)

    // Publish message
    err = rabbitmq.Publish(ch, q.Name, body)
    if err != nil {
        u.log.WithError(err).Error("Failed to publish message")
        return fmt.Errorf("failed to publish: %w", err)
    }

    u.log.WithField("queue", q.Name).Info("Message published successfully")
    return nil
}
```

**Example 2: Consumer - Processing Messages**

```go
// In a background job or goroutine
func (j *MessageConsumerJob) Run() {
    ctx := context.Background()
    j.log.Info("Starting RabbitMQ consumer")

    ch, err := j.deps.RabbitMQ.Conn.Channel()
    if err != nil {
        j.log.WithError(err).Fatal("Failed to create channel")
        return
    }
    defer ch.Close()

    // Declare queue
    queueName := "user-events"
    q, err := rabbitmq.DeclareQueue(ch, queueName, true)
    if err != nil {
        j.log.WithError(err).Fatal("Failed to declare queue")
        return
    }

    // Start consuming
    msgs, err := rabbitmq.Consume(ch, q.Name, false)
    if err != nil {
        j.log.WithError(err).Fatal("Failed to start consuming")
        return
    }

    j.log.WithField("queue", q.Name).Info("Waiting for messages...")

    for msg := range msgs {
        j.log.WithFields(logrus.Fields{
            "delivery_tag": msg.DeliveryTag,
            "body":         string(msg.Body),
        }).Debug("Received message")

        // Process message
        var event map[string]interface{}
        if err := json.Unmarshal(msg.Body, &event); err != nil {
            j.log.WithError(err).Error("Failed to parse message")
            msg.Nack(false, false) // Don't requeue invalid messages
            continue
        }

        // Business logic here
        if err := j.processEvent(ctx, event); err != nil {
            j.log.WithError(err).Error("Failed to process event")
            msg.Nack(false, true) // Requeue for retry
            continue
        }

        // Acknowledge successful processing
        msg.Ack(false)
        j.log.Info("Message processed successfully")
    }
}

func (j *MessageConsumerJob) processEvent(ctx context.Context, event map[string]interface{}) error {
    // Your business logic
    userID := int64(event["user_id"].(float64))
    eventType := event["event"].(string)
    
    j.log.WithFields(logrus.Fields{
        "user_id": userID,
        "event":   eventType,
    }).Info("Processing event")
    
    // Call usecase, repository, etc.
    return nil
}
```

**Example 3: Producer + Consumer Pattern**

```go
// Complete example: Async task processing
type TaskProcessor struct {
    deps *deps.Deps
    log  *logrus.Logger
}

func (t *TaskProcessor) SubmitTask(ctx context.Context, taskData interface{}) error {
    // Producer: Submit task to queue
    ch, err := t.deps.RabbitMQ.Conn.Channel()
    if err != nil {
        return err
    }
    defer ch.Close()

    q, _ := rabbitmq.DeclareQueue(ch, "tasks", true)
    body, _ := json.Marshal(taskData)
    
    return rabbitmq.Publish(ch, q.Name, body)
}

func (t *TaskProcessor) StartWorker(ctx context.Context) {
    // Consumer: Process tasks from queue
    ch, _ := t.deps.RabbitMQ.Conn.Channel()
    defer ch.Close()

    q, _ := rabbitmq.DeclareQueue(ch, "tasks", true)
    msgs, _ := rabbitmq.Consume(ch, q.Name, false)

    for msg := range msgs {
        var taskData map[string]interface{}
        json.Unmarshal(msg.Body, &taskData)
        
        // Process task
        if err := t.executeTask(ctx, taskData); err != nil {
            msg.Nack(false, true) // Requeue
        } else {
            msg.Ack(false)
        }
    }
}
```

{{- end}}
{{- if index .Includes "cron"}}
### Using Cron Jobs

Jobs are located in `internal/adapter/job/` and registered in `cmd/main.go`.

**Example job structure:**

```go
// In internal/adapter/job/my_job.go
package job

type MyJob struct {
    deps *deps.Deps
    log  *logrus.Logger
}

func NewMyJob(d *deps.Deps) *MyJob {
    return &MyJob{
        deps: d,
        log:  d.Log,
    }
}

func (j *MyJob) Run() {
    j.log.Info("Starting my custom job")
    // Job logic here
}

// In cmd/main.go
import "{{.ModuleName}}/internal/adapter/job"

myJob := job.NewMyJob(d)
_, err := d.Cron.AddJob("0 * * * *", myJob)
```

**Cron schedule examples:**
```
"*/5 * * * *"     # Every 5 minutes
"0 * * * *"       # Every hour
"0 0 * * *"       # Every day at midnight
"0 9 * * MON-FRI" # Weekdays at 9 AM
"@hourly"         # Every hour (shorthand)
"@daily"          # Every day at midnight
```

{{- end}}
{{- if index .Includes "kafka"}}
### Using Kafka

> **Note**: When you select Kafka, a consumer template is automatically generated at `internal/adapter/consumer/kafka_consumer.go`. You can customize it for your use case.

**Starting the Kafka Consumer (Clean Architecture):**

```go
// In cmd/main.go or internal/app/bootstrap.go
import (
    "{{.ModuleName}}/internal/adapter/consumer"
    "{{.ModuleName}}/internal/usecase"
)

// 1. Initialize usecases (business logic layer)
userUsecase := usecase.NewUserUsecase(userRepo, cacheRepo, d.Log)

// 2. Inject usecase into consumer (dependency injection)
if d.Kafka != nil {
    kafkaConsumer := consumer.NewKafkaConsumer(d, userUsecase)
    
    // Run as background goroutine
    go kafkaConsumer.Run()
    
    log.Printf("Kafka consumer started (topic: %s, group: %s)", 
        d.Kafka.Topic, d.Kafka.GroupID)
}
```

**Clean Architecture Flow:**
```
Kafka Message â†’ Consumer (Adapter) â†’ Usecase (Business Logic) â†’ Repository â†’ Database
```

**Consumer calls usecase methods:**
```go
// Inside consumer handler
func (c *KafkaConsumer) handleUserCreated(ctx context.Context, event map[string]interface{}) error {
    userID := int64(event["user_id"].(float64))
    
    // Consumer calls usecase (following Clean Architecture)
    user, err := c.userUsecase.GetUser(ctx, userID)
    if err != nil {
        return err
    }
    
    // All business logic goes through usecases
    return nil
}
```

**Graceful Shutdown (Recommended):**

```go
// In cmd/main.go
func main() {
    // ... setup dependencies ...
    
    // Start Kafka consumer
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    if d.Kafka != nil {
        kafkaConsumer := consumer.NewKafkaConsumer(d)
        go kafkaConsumer.RunWithContext(ctx) // Implement this method
    }
    
    // Wait for interrupt signal
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)
    <-sigChan
    
    log.Println("Shutting down gracefully...")
    cancel() // Cancel context to stop consumer
    time.Sleep(5 * time.Second) // Wait for cleanup
}
```

**Example 1: Producer - Publishing Messages**

```go
// In your usecase
func (u *UserUsecase) PublishUserEvent(ctx context.Context, userID int64, event string) error {
    u.log.WithFields(logrus.Fields{
        "user_id": userID,
        "event":   event,
    }).Info("Publishing event to Kafka")

    // Prepare message
    message := map[string]interface{}{
        "user_id":   userID,
        "event":     event,
        "timestamp": time.Now().Unix(),
    }
    body, _ := json.Marshal(message)

    // Create key for partitioning
    key := []byte(fmt.Sprintf("user-%d", userID))

    // Produce message
    err := u.deps.Kafka.Produce(ctx, key, body)
    if err != nil {
        u.log.WithError(err).Error("Failed to produce Kafka message")
        return fmt.Errorf("failed to produce to kafka: %w", err)
    }

    u.log.WithFields(logrus.Fields{
        "topic":  u.deps.Kafka.Topic,
        "key":    string(key),
    }).Info("Message published to Kafka successfully")

    return nil
}
```

**Example 2: Consumer - Processing Messages**

```go
// In a background job
func (j *KafkaConsumerJob) Run() {
    ctx := context.Background()
    j.log.Info("Starting Kafka consumer")

    if j.deps.Kafka == nil {
        j.log.Error("Kafka not initialized")
        return
    }

    j.log.WithFields(logrus.Fields{
        "topic":    j.deps.Kafka.Topic,
        "group_id": j.deps.Kafka.GroupID,
    }).Info("Consuming messages from Kafka")

    for {
        // Read message
        msg, err := j.deps.Kafka.Reader.ReadMessage(ctx)
        if err != nil {
            j.log.WithError(err).Error("Failed to read Kafka message")
            time.Sleep(time.Second) // Backoff
            continue
        }

        j.log.WithFields(logrus.Fields{
            "topic":     msg.Topic,
            "partition": msg.Partition,
            "offset":    msg.Offset,
            "key":       string(msg.Key),
        }).Debug("Received Kafka message")

        // Process message
        var event map[string]interface{}
        if err := json.Unmarshal(msg.Value, &event); err != nil {
            j.log.WithError(err).Error("Failed to parse message")
            continue // Skip invalid message
        }

        // Business logic
        if err := j.processEvent(ctx, event); err != nil {
            j.log.WithError(err).Error("Failed to process event")
            // Kafka auto-commits, or you can implement retry logic
            continue
        }

        j.log.WithFields(logrus.Fields{
            "offset": msg.Offset,
            "key":    string(msg.Key),
        }).Info("Message processed successfully")
    }
}

func (j *KafkaConsumerJob) processEvent(ctx context.Context, event map[string]interface{}) error {
    userID := int64(event["user_id"].(float64))
    eventType := event["event"].(string)

    j.log.WithFields(logrus.Fields{
        "user_id": userID,
        "event":   eventType,
    }).Info("Processing Kafka event")

    // Call usecase, repository, etc.
    return nil
}
```

**Example 3: Event-Driven Architecture Pattern**

```go
// Complete example: User service publishes, notification service consumes

// 1. User Service: Produce event when user is created
func (u *UserUsecase) CreateUser(ctx context.Context, user *domain.User) error {
    // Create user in database
    if err := u.userRepo.Create(ctx, user); err != nil {
        return err
    }

    // Publish event to Kafka
    event := map[string]interface{}{
        "event_type": "user.created",
        "user_id":    user.ID,
        "email":      user.Email,
        "name":       user.Name,
        "created_at": time.Now().Unix(),
    }
    eventData, _ := json.Marshal(event)
    key := []byte(fmt.Sprintf("user-%d", user.ID))

    if err := u.deps.Kafka.Produce(ctx, key, eventData); err != nil {
        u.log.WithError(err).Error("Failed to publish user.created event")
        // Non-critical: Don't fail user creation if event publishing fails
    }

    u.log.WithField("user_id", user.ID).Info("User created and event published")
    return nil
}

// 2. Notification Service: Consume events and send notifications
type NotificationConsumer struct {
    deps *deps.Deps
    log  *logrus.Logger
}

func (n *NotificationConsumer) Start(ctx context.Context) {
    n.log.Info("Starting notification consumer")

    for {
        msg, err := n.deps.Kafka.Reader.ReadMessage(ctx)
        if err != nil {
            n.log.WithError(err).Error("Failed to read message")
            continue
        }

        var event map[string]interface{}
        json.Unmarshal(msg.Value, &event)

        eventType := event["event_type"].(string)

        switch eventType {
        case "user.created":
            n.sendWelcomeEmail(ctx, event)
        case "user.updated":
            n.sendUpdateNotification(ctx, event)
        default:
            n.log.WithField("event_type", eventType).Warn("Unknown event type")
        }
    }
}

func (n *NotificationConsumer) sendWelcomeEmail(ctx context.Context, event map[string]interface{}) error {
    email := event["email"].(string)
    name := event["name"].(string)

    n.log.WithFields(logrus.Fields{
        "email": email,
        "name":  name,
    }).Info("Sending welcome email")

    // Send email logic here
    return nil
}
```

**Example 4: Parallel Producer/Consumer**

```go
// Run producer and consumer in parallel (e.g., in cmd/main.go)
func setupKafka(d *deps.Deps) {
    // Start consumer in goroutine
    go func() {
        consumer := &KafkaConsumerJob{deps: d, log: d.Log}
        consumer.Run()
    }()

    // Producer is called on-demand from usecases
    // e.g., when user performs an action
}
```

**Configuration for Kafka:**

```json
{
  "kafka": {
    "brokers": ["localhost:9092"],
    "topic": "user-events",
    "groupid": "user-service-group",
    "balancer": "hash"
  }
}
```

**Environment variables:**
```bash
KAFKA_BROKERS=kafka-1:9092,kafka-2:9092,kafka-3:9092
KAFKA_TOPIC=production-events
KAFKA_GROUPID=production-consumer-group
```

{{- end}}

{{- if index .Includes "activemq"}}
### Using ActiveMQ (STOMP)

> **Note**: When you select ActiveMQ, a consumer template is automatically generated at `internal/adapter/consumer/activemq_consumer.go`. You can customize it for your use case.

**Starting the ActiveMQ Consumer (Clean Architecture):**

```go
// In cmd/main.go or internal/app/bootstrap.go
import (
    "{{.ModuleName}}/internal/adapter/consumer"
    "{{.ModuleName}}/internal/usecase"
)

// 1. Initialize usecases (business logic layer)
userUsecase := usecase.NewUserUsecase(userRepo, cacheRepo, d.Log)

// 2. Inject usecase into consumer (dependency injection)
if d.ActiveMQ != nil {
    activemqConsumer := consumer.NewActiveMQConsumer(d, userUsecase)
    
    // Run as background goroutine
    go activemqConsumer.Run()
    
    log.Println("ActiveMQ consumer started")
}
```

**Clean Architecture Flow:**
```
ActiveMQ Message â†’ Consumer (Adapter) â†’ Usecase (Business Logic) â†’ Repository â†’ Database
```

**Consumer calls usecase methods:**
```go
// Inside consumer handler
func (c *ActiveMQConsumer) handleUserCreated(ctx context.Context, event map[string]interface{}) error {
    userID := int64(event["user_id"].(float64))
    
    // Consumer calls usecase (following Clean Architecture)
    user, err := c.userUsecase.GetUser(ctx, userID)
    if err != nil {
        return err
    }
    
    // Additional business logic via usecases
    return nil
}
```

**Example 1: Producer - Sending Messages**

```go
// In your usecase or handler
func (u *UserUsecase) PublishUserEvent(ctx context.Context, userID int64, event string) error {
    u.log.WithFields(logrus.Fields{
        "user_id": userID,
        "event":   event,
    }).Info("Publishing user event to ActiveMQ")

    if u.deps.ActiveMQ == nil {
        return fmt.Errorf("activemq not initialized")
    }

    // Prepare message
    message := map[string]interface{}{
        "type":      event,
        "user_id":   userID,
        "timestamp": time.Now().Format(time.RFC3339),
    }
    body, _ := json.Marshal(message)

    // Send to queue (STOMP protocol)
    destination := "/queue/user-events"
    err := u.deps.ActiveMQ.Conn.Send(
        destination,
        "application/json",
        body,
        stomp.SendOpt.Header("persistent", "true"),
    )
    
    if err != nil {
        u.log.WithError(err).Error("Failed to send message to ActiveMQ")
        return fmt.Errorf("failed to send message: %w", err)
    }

    u.log.WithField("destination", destination).Info("Message sent successfully")
    return nil
}
```

**Example 2: Consumer - Processing Messages**

```go
// The generated consumer template handles this automatically
// Located at: internal/adapter/consumer/activemq_consumer.go

// Example custom event handler:
func (c *ActiveMQConsumer) handleOrderPlaced(ctx context.Context, event map[string]interface{}) error {
    orderID, ok := event["order_id"].(string)
    if !ok {
        c.log.Warn("Invalid order_id in event")
        return nil
    }

    c.log.WithField("order_id", orderID).Info("Processing order.placed event")

    // Call usecase for business logic
    // Example: Update inventory, send notification, etc.
    
    return nil
}
```

**Example 3: Topic Publish/Subscribe Pattern**

```go
// Publisher
func (u *UserUsecase) BroadcastEvent(ctx context.Context, topic string, data interface{}) error {
    body, _ := json.Marshal(data)
    
    // Use /topic/ prefix for pub/sub pattern
    destination := fmt.Sprintf("/topic/%s", topic)
    
    err := u.deps.ActiveMQ.Conn.Send(
        destination,
        "application/json",
        body,
    )
    
    return err
}

// Subscriber
func (c *ActiveMQConsumer) SubscribeToTopic(topic string) error {
    destination := fmt.Sprintf("/topic/%s", topic)
    
    sub, err := c.deps.ActiveMQ.Conn.Subscribe(
        destination,
        stomp.AckClientIndividual,
    )
    if err != nil {
        return err
    }
    
    // Process messages
    go func() {
        for msg := range sub.C {
            if msg == nil {
                break
            }
            
            // Process message
            c.log.WithField("topic", topic).Debug("Received message from topic")
            
            // ACK
            c.deps.ActiveMQ.Conn.Ack(msg)
        }
    }()
    
    return nil
}
```

**Example 4: Request-Reply Pattern**

```go
// Client (Request)
func (u *UserUsecase) SendRequest(ctx context.Context, requestData interface{}) (interface{}, error) {
    replyQueue := "/queue/reply-" + uuid.New().String()
    
    // Subscribe to reply queue
    sub, err := u.deps.ActiveMQ.Conn.Subscribe(replyQueue, stomp.AckAuto)
    if err != nil {
        return nil, err
    }
    defer sub.Unsubscribe()
    
    // Send request with reply-to header
    body, _ := json.Marshal(requestData)
    err = u.deps.ActiveMQ.Conn.Send(
        "/queue/requests",
        "application/json",
        body,
        stomp.SendOpt.Header("reply-to", replyQueue),
    )
    if err != nil {
        return nil, err
    }
    
    // Wait for reply (with timeout)
    select {
    case msg := <-sub.C:
        var response interface{}
        json.Unmarshal(msg.Body, &response)
        return response, nil
    case <-time.After(5 * time.Second):
        return nil, fmt.Errorf("request timeout")
    }
}

// Server (Reply)
func (c *ActiveMQConsumer) handleRequest(msg *stomp.Message) error {
    replyTo := msg.Header.Get("reply-to")
    
    // Process request
    var request map[string]interface{}
    json.Unmarshal(msg.Body, &request)
    
    // Prepare response
    response := map[string]interface{}{
        "status": "success",
        "data":   "processed",
    }
    body, _ := json.Marshal(response)
    
    // Send reply
    return c.deps.ActiveMQ.Conn.Send(replyTo, "application/json", body)
}
```

**Graceful Shutdown:**

```go
// In main.go
func main() {
    // ... initialization ...
    
    // Start consumer
    if d.ActiveMQ != nil {
        activemqConsumer := consumer.NewActiveMQConsumer(d, userUsecase)
        go activemqConsumer.Run()
    }
    
    // Wait for interrupt signal
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    <-quit
    
    log.Println("Shutting down gracefully...")
    
    // Close ActiveMQ connection
    if d.ActiveMQ != nil {
        if err := d.ActiveMQ.Close(); err != nil {
            log.Printf("Error closing ActiveMQ: %v", err)
        }
    }
    
    log.Println("Shutdown complete")
}
```

**Key Features:**

1. **STOMP Protocol**: Uses `github.com/go-stomp/stomp` for connectivity
2. **Queue & Topic Support**: 
   - `/queue/name` for point-to-point messaging
   - `/topic/name` for publish-subscribe pattern
3. **Message Acknowledgment**: 
   - `stomp.AckAuto` for automatic ACK
   - `stomp.AckClientIndividual` for manual ACK/NACK
4. **Clean Architecture**: Consumers call usecases for business logic
5. **Context Propagation**: Context passed through all layers
6. **Structured Logging**: Logrus with contextual fields

**Configuration:**

```yaml
activemq:
  addr: "localhost:61613"      # STOMP port
  login: "admin"               # Username (optional)
  passcode: "admin"            # Password (optional)
```

{{- end}}

## Testing

Run tests:

```bash
go test ./...
```

With coverage:

```bash
go test -cover ./...
```

## Observability

{{- if index .Includes "opentelemetry"}}
### Distributed Tracing

This project uses OpenTelemetry for distributed tracing:

- Traces are propagated through all layers via `context.Context`
- Each layer creates spans: `handler.GetUser`, `usecase.GetUser`, `repository.GetByID`
- Errors are recorded in spans for better debugging

Configure via environment variables:
```bash
OPENTELEMETRY_ENDPOINT=http://localhost:4318
OPENTELEMETRY_SERVICENAME={{.ProjectName}}
OPENTELEMETRY_SAMPLERATIO=1.0
```
{{- end}}

### Structured Logging

All layers include structured logging with contextual information:

```bash
# View logs in JSON format
go run cmd/main.go | jq

# Filter by log level
go run cmd/main.go | jq 'select(.level=="error")'

# Filter by user_id
go run cmd/main.go | jq 'select(.user_id==123)'
```

### Middleware

Built-in middleware for production-ready applications:

1. **Logging Middleware**: Logs all HTTP requests/responses with duration
2. **Tracing Middleware**: Creates spans for each HTTP request{{- if index .Includes "opentelemetry"}} (OpenTelemetry){{- end}}
3. **Rate Limiting**: Prevents abuse with configurable limits (10 req/sec default)

## Troubleshooting

### Enable Debug Logging

For detailed logs during development:

```bash
LOG_LEVEL=debug go run cmd/main.go
```

### Port Already in Use

Change the port via environment variable:

```bash
{{- if eq .Framework "echo"}}
ECHO_PORT=9000 go run cmd/main.go
{{- else if eq .Framework "gin"}}
GIN_PORT=9000 go run cmd/main.go
{{- else if eq .Framework "fiber"}}
FIBER_PORT=9000 go run cmd/main.go
{{- end}}
```

### Database Connection Error

Check your connection string in `config/config.json` or set via env var. Enable debug logging to see detailed connection attempts.

### RabbitMQ Connection Error

Ensure RabbitMQ is running and the URL is correct:

```bash
RABBITMQ_URL=amqp://guest:guest@localhost:5672/ go run cmd/main.go
```

### Viewing Structured Logs

Use `jq` to parse JSON logs:

```bash
# Pretty print
go run cmd/main.go | jq

# Show only errors
go run cmd/main.go | jq 'select(.level=="error")'

# Follow logs with grep
go run cmd/main.go 2>&1 | grep "User created"
```

## License

MIT

## Generated by

Go Project Generator v1.0
